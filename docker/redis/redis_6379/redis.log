1:C 13 Mar 2020 13:31:21.347 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
1:C 13 Mar 2020 13:31:21.348 # Redis version=5.0.7, bits=64, commit=00000000, modified=0, pid=1, just started
1:C 13 Mar 2020 13:31:21.348 # Configuration loaded
1:M 13 Mar 2020 13:31:21.348 * No cluster configuration found, I'm c2373db38bcbc51190f9b1c3e65aebd52f6300bd
                _._                                                  
           _.-``__ ''-._                                             
      _.-``    `.  `_.  ''-._           Redis 5.0.7 (00000000/0) 64 bit
  .-`` .-```.  ```\/    _.,_ ''-._                                   
 (    '      ,       .-`  | `,    )     Running in cluster mode
 |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379
 |    `-._   `._    /     _.-'    |     PID: 1
  `-._    `-._  `-./  _.-'    _.-'                                   
 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
 |    `-._`-._        _.-'_.-'    |           http://redis.io        
  `-._    `-._`-.__.-'_.-'    _.-'                                   
 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
 |    `-._`-._        _.-'_.-'    |                                  
  `-._    `-._`-.__.-'_.-'    _.-'                                   
      `-._    `-.__.-'    _.-'                                       
          `-._        _.-'                                           
              `-.__.-'                                               

1:M 13 Mar 2020 13:31:21.366 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
1:M 13 Mar 2020 13:31:21.366 # Server initialized
1:M 13 Mar 2020 13:31:21.366 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
1:M 13 Mar 2020 13:31:21.366 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.
1:M 13 Mar 2020 13:31:21.367 * Ready to accept connections
1:M 13 Mar 2020 13:35:23.938 # configEpoch set to 1 via CLUSTER SET-CONFIG-EPOCH
1:M 13 Mar 2020 13:35:23.974 # IP address for this node updated to 172.18.0.2
1:M 13 Mar 2020 13:35:28.488 # Cluster state changed: ok
1:M 13 Mar 2020 13:35:30.556 * Replica 211.159.216.48:6384 asks for synchronization
1:M 13 Mar 2020 13:35:30.557 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for '5033efd6def534f6eab714d2d9f2dd0f96148c37', my replication IDs are 'fcc2c3a7b624e6d2f491402f526e4e29369306df' and '0000000000000000000000000000000000000000')
1:M 13 Mar 2020 13:35:30.557 * Starting BGSAVE for SYNC with target: disk
1:M 13 Mar 2020 13:35:30.557 * Background saving started by pid 23
23:C 13 Mar 2020 13:35:30.565 * DB saved on disk
23:C 13 Mar 2020 13:35:30.566 * RDB: 4 MB of memory used by copy-on-write
1:M 13 Mar 2020 13:35:30.594 * Background saving terminated with success
1:M 13 Mar 2020 13:35:30.594 * Synchronization with replica 211.159.216.48:6384 succeeded
1:M 13 Mar 2020 13:59:56.723 # New configEpoch set to 7
1:M 13 Mar 2020 13:59:56.724 # configEpoch updated after importing slot 10923
1:signal-handler (1584108145) Received SIGTERM scheduling shutdown...
1:M 13 Mar 2020 14:02:25.675 # User requested shutdown...
1:M 13 Mar 2020 14:02:25.675 * Calling fsync() on the AOF file.
1:M 13 Mar 2020 14:02:25.676 * Removing the pid file.
1:M 13 Mar 2020 14:02:25.676 # Redis is now ready to exit, bye bye...
1:C 13 Mar 2020 14:04:10.223 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
1:C 13 Mar 2020 14:04:10.223 # Redis version=5.0.7, bits=64, commit=00000000, modified=0, pid=1, just started
1:C 13 Mar 2020 14:04:10.223 # Configuration loaded
1:M 13 Mar 2020 14:04:10.224 * Node configuration loaded, I'm c2373db38bcbc51190f9b1c3e65aebd52f6300bd
                _._                                                  
           _.-``__ ''-._                                             
      _.-``    `.  `_.  ''-._           Redis 5.0.7 (00000000/0) 64 bit
  .-`` .-```.  ```\/    _.,_ ''-._                                   
 (    '      ,       .-`  | `,    )     Running in cluster mode
 |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379
 |    `-._   `._    /     _.-'    |     PID: 1
  `-._    `-._  `-./  _.-'    _.-'                                   
 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
 |    `-._`-._        _.-'_.-'    |           http://redis.io        
  `-._    `-._`-.__.-'_.-'    _.-'                                   
 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
 |    `-._`-._        _.-'_.-'    |                                  
  `-._    `-._`-.__.-'_.-'    _.-'                                   
      `-._    `-.__.-'    _.-'                                       
          `-._        _.-'                                           
              `-.__.-'                                               

1:M 13 Mar 2020 14:04:10.224 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
1:M 13 Mar 2020 14:04:10.224 # Server initialized
1:M 13 Mar 2020 14:04:10.224 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
1:M 13 Mar 2020 14:04:10.224 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.
1:M 13 Mar 2020 14:04:10.224 * DB loaded from append only file: 0.000 seconds
1:M 13 Mar 2020 14:04:10.224 * Ready to accept connections
1:M 13 Mar 2020 14:04:10.228 # Configuration change detected. Reconfiguring myself as a replica of f16a0f69702d233768cec8075f6bdb8d7677c7fc
1:S 13 Mar 2020 14:04:10.228 * Before turning into a replica, using my master parameters to synthesize a cached master: I may be able to synchronize with the new master with just a partial transfer.
1:S 13 Mar 2020 14:04:10.228 # Cluster state changed: ok
1:S 13 Mar 2020 14:04:11.228 * Connecting to MASTER 211.159.216.48:6384
1:S 13 Mar 2020 14:04:11.228 * MASTER <-> REPLICA sync started
1:S 13 Mar 2020 14:04:11.229 * Non blocking connect for SYNC fired the event.
1:S 13 Mar 2020 14:04:11.229 * Master replied to PING, replication can continue...
1:S 13 Mar 2020 14:04:11.231 * Trying a partial resynchronization (request 9999b6bf04c536a3514ea5d1bdb0375ecae8beaa:1).
1:S 13 Mar 2020 14:04:11.234 * Full resync from master: 571ede5185b35cbb15a10c1704851d7ab9feef11:2464
1:S 13 Mar 2020 14:04:11.234 * Discarding previously cached master state.
1:S 13 Mar 2020 14:04:11.262 * MASTER <-> REPLICA sync: receiving 245 bytes from master
1:S 13 Mar 2020 14:04:11.262 * MASTER <-> REPLICA sync: Flushing old data
1:S 13 Mar 2020 14:04:11.263 * MASTER <-> REPLICA sync: Loading DB in memory
1:S 13 Mar 2020 14:04:11.263 * MASTER <-> REPLICA sync: Finished with success
1:S 13 Mar 2020 14:04:11.264 * Background append only file rewriting started by pid 15
1:S 13 Mar 2020 14:04:11.293 * AOF rewrite child asks to stop sending diffs.
15:C 13 Mar 2020 14:04:11.293 * Parent agreed to stop sending diffs. Finalizing AOF...
15:C 13 Mar 2020 14:04:11.293 * Concatenating 0.00 MB of AOF diff received from parent.
15:C 13 Mar 2020 14:04:11.294 * SYNC append only file rewrite performed
15:C 13 Mar 2020 14:04:11.294 * AOF rewrite: 4 MB of memory used by copy-on-write
1:S 13 Mar 2020 14:04:11.329 * Background AOF rewrite terminated with success
1:S 13 Mar 2020 14:04:11.330 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)
1:S 13 Mar 2020 14:04:11.330 * Background AOF rewrite finished successfully
1:signal-handler (1584500404) Received SIGTERM scheduling shutdown...
1:S 18 Mar 2020 03:00:04.122 # User requested shutdown...
1:S 18 Mar 2020 03:00:04.122 * Calling fsync() on the AOF file.
1:S 18 Mar 2020 03:00:04.129 * Removing the pid file.
1:S 18 Mar 2020 03:00:04.129 # Redis is now ready to exit, bye bye...
1:C 18 Mar 2020 03:07:48.753 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
1:C 18 Mar 2020 03:07:48.753 # Redis version=5.0.7, bits=64, commit=00000000, modified=0, pid=1, just started
1:C 18 Mar 2020 03:07:48.753 # Configuration loaded
1:M 18 Mar 2020 03:07:48.754 * Node configuration loaded, I'm c2373db38bcbc51190f9b1c3e65aebd52f6300bd
                _._                                                  
           _.-``__ ''-._                                             
      _.-``    `.  `_.  ''-._           Redis 5.0.7 (00000000/0) 64 bit
  .-`` .-```.  ```\/    _.,_ ''-._                                   
 (    '      ,       .-`  | `,    )     Running in cluster mode
 |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379
 |    `-._   `._    /     _.-'    |     PID: 1
  `-._    `-._  `-./  _.-'    _.-'                                   
 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
 |    `-._`-._        _.-'_.-'    |           http://redis.io        
  `-._    `-._`-.__.-'_.-'    _.-'                                   
 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
 |    `-._`-._        _.-'_.-'    |                                  
  `-._    `-._`-.__.-'_.-'    _.-'                                   
      `-._    `-.__.-'    _.-'                                       
          `-._        _.-'                                           
              `-.__.-'                                               

1:M 18 Mar 2020 03:07:48.754 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
1:M 18 Mar 2020 03:07:48.754 # Server initialized
1:M 18 Mar 2020 03:07:48.754 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
1:M 18 Mar 2020 03:07:48.754 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.
1:M 18 Mar 2020 03:07:48.755 * Reading RDB preamble from AOF file...
1:M 18 Mar 2020 03:07:48.755 * Reading the remaining AOF tail...
1:M 18 Mar 2020 03:07:48.755 * DB loaded from append only file: 0.000 seconds
1:M 18 Mar 2020 03:07:48.755 * Ready to accept connections
1:S 18 Mar 2020 03:07:48.756 * Before turning into a replica, using my master parameters to synthesize a cached master: I may be able to synchronize with the new master with just a partial transfer.
1:S 18 Mar 2020 03:07:48.756 # Cluster state changed: ok
1:S 18 Mar 2020 03:07:49.769 * Connecting to MASTER 211.159.216.48:6384
1:S 18 Mar 2020 03:07:49.769 * MASTER <-> REPLICA sync started
1:S 18 Mar 2020 03:07:49.769 # Error condition on socket for SYNC: Connection refused
1:S 18 Mar 2020 03:07:50.795 * Connecting to MASTER 211.159.216.48:6384
1:S 18 Mar 2020 03:07:50.795 * MASTER <-> REPLICA sync started
1:S 18 Mar 2020 03:07:50.796 * Non blocking connect for SYNC fired the event.
1:S 18 Mar 2020 03:07:50.802 * Master replied to PING, replication can continue...
1:S 18 Mar 2020 03:07:50.806 * Trying a partial resynchronization (request f228352699d923328713d3dbe708d292cc65ea47:1).
1:S 18 Mar 2020 03:07:50.808 * Full resync from master: 9aad2566a298520736f2a8cde5f2e0b7c1334657:0
1:S 18 Mar 2020 03:07:50.809 * Discarding previously cached master state.
1:S 18 Mar 2020 03:07:50.834 * MASTER <-> REPLICA sync: receiving 348 bytes from master
1:S 18 Mar 2020 03:07:50.835 * MASTER <-> REPLICA sync: Flushing old data
1:S 18 Mar 2020 03:07:50.838 * MASTER <-> REPLICA sync: Loading DB in memory
1:S 18 Mar 2020 03:07:50.839 * MASTER <-> REPLICA sync: Finished with success
1:S 18 Mar 2020 03:07:50.839 * Background append only file rewriting started by pid 15
1:S 18 Mar 2020 03:07:50.893 * AOF rewrite child asks to stop sending diffs.
15:C 18 Mar 2020 03:07:50.894 * Parent agreed to stop sending diffs. Finalizing AOF...
15:C 18 Mar 2020 03:07:50.894 * Concatenating 0.00 MB of AOF diff received from parent.
15:C 18 Mar 2020 03:07:50.896 * SYNC append only file rewrite performed
15:C 18 Mar 2020 03:07:50.897 * AOF rewrite: 4 MB of memory used by copy-on-write
1:S 18 Mar 2020 03:07:50.997 * Background AOF rewrite terminated with success
1:S 18 Mar 2020 03:07:50.997 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)
1:S 18 Mar 2020 03:07:50.998 * Background AOF rewrite finished successfully
1:S 18 Mar 2020 03:41:27.173 # Cluster state changed: fail
1:S 18 Mar 2020 03:41:27.441 # Cluster state changed: ok
1:S 18 Mar 2020 03:41:28.497 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about f16a0f69702d233768cec8075f6bdb8d7677c7fc
1:S 18 Mar 2020 03:41:28.497 # Start of election delayed for 888 milliseconds (rank #0, offset 2814).
1:S 18 Mar 2020 03:41:28.497 # Cluster state changed: fail
1:S 18 Mar 2020 03:41:29.440 # Starting a failover election for epoch 10.
1:S 18 Mar 2020 03:41:31.321 * FAIL message received from f16a0f69702d233768cec8075f6bdb8d7677c7fc about 53cbf4b5efdef7e11e54519a22ce0237989e80b5
1:S 18 Mar 2020 03:41:32.623 * Clear FAIL state for node 53cbf4b5efdef7e11e54519a22ce0237989e80b5: replica is reachable again.
1:S 18 Mar 2020 03:41:33.396 # Failover election won: I'm the new master.
1:S 18 Mar 2020 03:41:33.396 # configEpoch set to 10 after successful failover
1:M 18 Mar 2020 03:41:33.396 # Setting secondary replication ID to 9aad2566a298520736f2a8cde5f2e0b7c1334657, valid up to offset: 2815. New replication ID is 38e8c796b3c1f838d766c5f075d2b36adf268ac5
1:M 18 Mar 2020 03:41:33.396 # Connection with master lost.
1:M 18 Mar 2020 03:41:33.396 * Caching the disconnected master state.
1:M 18 Mar 2020 03:41:33.396 * Discarding previously cached master state.
1:M 18 Mar 2020 03:41:33.520 # Cluster state changed: ok
1:M 18 Mar 2020 03:41:34.370 * Replica 211.159.216.48:6384 asks for synchronization
1:M 18 Mar 2020 03:41:34.370 * Partial resynchronization request from 211.159.216.48:6384 accepted. Sending 0 bytes of backlog starting from offset 2815.
1:M 18 Mar 2020 03:41:34.390 * Clear FAIL state for node f16a0f69702d233768cec8075f6bdb8d7677c7fc: replica is reachable again.
1:M 18 Mar 2020 04:04:25.144 # Cluster state changed: fail
1:M 18 Mar 2020 04:04:28.541 * Marking node f16a0f69702d233768cec8075f6bdb8d7677c7fc as failing (quorum reached).
1:M 18 Mar 2020 04:04:28.542 * Marking node 07358e9560cb6059495fbaf2bf6b831695920b6e as failing (quorum reached).
1:M 18 Mar 2020 04:04:29.200 * FAIL message received from 07358e9560cb6059495fbaf2bf6b831695920b6e about 5e79d143e1773f99d92c5acb70ccda5a38dfd19f
1:M 18 Mar 2020 04:04:29.421 * Clear FAIL state for node f16a0f69702d233768cec8075f6bdb8d7677c7fc: replica is reachable again.
1:M 18 Mar 2020 04:04:30.148 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:M 18 Mar 2020 04:04:32.181 # Failover auth granted to 53cbf4b5efdef7e11e54519a22ce0237989e80b5 for epoch 11
1:M 18 Mar 2020 04:04:33.591 # Cluster state changed: ok
1:M 18 Mar 2020 04:04:33.693 * Clear FAIL state for node 07358e9560cb6059495fbaf2bf6b831695920b6e: master without slots is reachable again.
1:M 18 Mar 2020 04:33:42.049 # Cluster state changed: fail
1:M 18 Mar 2020 04:33:45.122 * Marking node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b as failing (quorum reached).
1:M 18 Mar 2020 04:33:45.122 * Marking node 07358e9560cb6059495fbaf2bf6b831695920b6e as failing (quorum reached).
1:M 18 Mar 2020 04:33:47.867 * Marking node 53cbf4b5efdef7e11e54519a22ce0237989e80b5 as failing (quorum reached).
1:M 18 Mar 2020 04:33:52.513 * Marking node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f as failing (quorum reached).
1:M 18 Mar 2020 04:33:57.023 # Failover auth denied to 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: its master is up
1:M 18 Mar 2020 04:33:57.804 * Marking node 89136814ea739a99417054dbf41ea0ded4817909 as failing (quorum reached).
1:M 18 Mar 2020 04:34:00.779 * Clear FAIL state for node 07358e9560cb6059495fbaf2bf6b831695920b6e: replica is reachable again.
1:M 18 Mar 2020 04:34:02.873 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:M 18 Mar 2020 04:34:02.874 # Failover auth granted to 07358e9560cb6059495fbaf2bf6b831695920b6e for epoch 15
1:M 18 Mar 2020 04:34:03.229 * FAIL message received from 53cbf4b5efdef7e11e54519a22ce0237989e80b5 about eb97b4baffba703c1a0b106c8c26c8aeb122c114
1:M 18 Mar 2020 04:34:04.046 * FAIL message received from 53cbf4b5efdef7e11e54519a22ce0237989e80b5 about 5e79d143e1773f99d92c5acb70ccda5a38dfd19f
1:M 18 Mar 2020 04:34:04.967 * Clear FAIL state for node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b: replica is reachable again.
1:M 18 Mar 2020 04:34:07.148 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:M 18 Mar 2020 04:34:10.153 * Clear FAIL state for node 53cbf4b5efdef7e11e54519a22ce0237989e80b5: is reachable again and nobody is serving its slots after some time.
1:M 18 Mar 2020 04:34:11.245 * Clear FAIL state for node 89136814ea739a99417054dbf41ea0ded4817909: is reachable again and nobody is serving its slots after some time.
1:M 18 Mar 2020 04:34:16.469 * Clear FAIL state for node eb97b4baffba703c1a0b106c8c26c8aeb122c114: is reachable again and nobody is serving its slots after some time.
1:M 18 Mar 2020 04:34:16.469 # Cluster state changed: ok
1:M 18 Mar 2020 04:34:24.542 * FAIL message received from 89136814ea739a99417054dbf41ea0ded4817909 about 5e79d143e1773f99d92c5acb70ccda5a38dfd19f
1:M 18 Mar 2020 04:34:25.314 * Marking node 07358e9560cb6059495fbaf2bf6b831695920b6e as failing (quorum reached).
1:M 18 Mar 2020 04:34:25.787 * FAIL message received from 89136814ea739a99417054dbf41ea0ded4817909 about eb97b4baffba703c1a0b106c8c26c8aeb122c114
1:M 18 Mar 2020 04:34:25.787 # Cluster state changed: fail
1:M 18 Mar 2020 04:34:26.291 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:M 18 Mar 2020 04:34:36.650 * Clear FAIL state for node 07358e9560cb6059495fbaf2bf6b831695920b6e: replica is reachable again.
1:M 18 Mar 2020 04:34:38.292 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 5e79d143e1773f99d92c5acb70ccda5a38dfd19f
1:M 18 Mar 2020 04:34:38.313 * Marking node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b as failing (quorum reached).
1:M 18 Mar 2020 04:34:39.637 * Clear FAIL state for node eb97b4baffba703c1a0b106c8c26c8aeb122c114: is reachable again and nobody is serving its slots after some time.
1:M 18 Mar 2020 04:34:39.637 * Marking node 53cbf4b5efdef7e11e54519a22ce0237989e80b5 as failing (quorum reached).
1:M 18 Mar 2020 04:34:44.784 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:M 18 Mar 2020 04:34:49.087 * FAIL message received from 53cbf4b5efdef7e11e54519a22ce0237989e80b5 about 07358e9560cb6059495fbaf2bf6b831695920b6e
1:M 18 Mar 2020 04:34:59.446 * Clear FAIL state for node 53cbf4b5efdef7e11e54519a22ce0237989e80b5: is reachable again and nobody is serving its slots after some time.
1:M 18 Mar 2020 04:34:59.446 * Marking node f16a0f69702d233768cec8075f6bdb8d7677c7fc as failing (quorum reached).
1:M 18 Mar 2020 04:35:00.341 * Marking node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f as failing (quorum reached).
1:M 18 Mar 2020 04:35:02.138 # Failover auth denied to 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b: its master is up
1:M 18 Mar 2020 04:35:05.243 * Clear FAIL state for node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b: replica is reachable again.
1:M 18 Mar 2020 04:35:06.388 # Cluster state changed: ok
1:M 18 Mar 2020 04:35:06.993 # Cluster state changed: fail
1:M 18 Mar 2020 04:35:10.182 * Marking node 53cbf4b5efdef7e11e54519a22ce0237989e80b5 as failing (quorum reached).
1:M 18 Mar 2020 04:35:12.470 * Clear FAIL state for node f16a0f69702d233768cec8075f6bdb8d7677c7fc: replica is reachable again.
1:M 18 Mar 2020 04:35:13.371 # Failover auth denied to 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: reqEpoch (16) < curEpoch(17)
1:M 18 Mar 2020 04:35:16.333 * FAIL message received from 89136814ea739a99417054dbf41ea0ded4817909 about f16a0f69702d233768cec8075f6bdb8d7677c7fc
1:M 18 Mar 2020 04:35:20.189 # Failover auth denied to 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: its master is up
1:M 18 Mar 2020 04:35:23.801 * Clear FAIL state for node f16a0f69702d233768cec8075f6bdb8d7677c7fc: replica is reachable again.
1:M 18 Mar 2020 04:35:24.127 * Marking node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b as failing (quorum reached).
1:M 18 Mar 2020 04:35:25.353 * FAIL message received from 89136814ea739a99417054dbf41ea0ded4817909 about f16a0f69702d233768cec8075f6bdb8d7677c7fc
1:M 18 Mar 2020 04:35:25.383 * Marking node 89136814ea739a99417054dbf41ea0ded4817909 as failing (quorum reached).
1:M 18 Mar 2020 04:35:25.715 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:M 18 Mar 2020 04:35:25.765 * Clear FAIL state for node f16a0f69702d233768cec8075f6bdb8d7677c7fc: replica is reachable again.
1:M 18 Mar 2020 04:35:26.369 # Failover auth denied to 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: its master is up
1:M 18 Mar 2020 04:35:27.488 # Failover auth granted to 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b for epoch 19
1:M 18 Mar 2020 04:35:29.601 * FAIL message received from 89136814ea739a99417054dbf41ea0ded4817909 about eb97b4baffba703c1a0b106c8c26c8aeb122c114
1:M 18 Mar 2020 04:35:30.831 * FAIL message received from 89136814ea739a99417054dbf41ea0ded4817909 about f16a0f69702d233768cec8075f6bdb8d7677c7fc
1:M 18 Mar 2020 04:35:31.725 * Clear FAIL state for node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b: replica is reachable again.
1:M 18 Mar 2020 04:35:32.237 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 5e79d143e1773f99d92c5acb70ccda5a38dfd19f
1:M 18 Mar 2020 04:35:32.442 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b
1:M 18 Mar 2020 04:35:33.627 * Clear FAIL state for node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b: replica is reachable again.
1:M 18 Mar 2020 04:35:33.799 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:M 18 Mar 2020 04:35:34.933 * Clear FAIL state for node 53cbf4b5efdef7e11e54519a22ce0237989e80b5: is reachable again and nobody is serving its slots after some time.
1:M 18 Mar 2020 04:35:35.793 * Clear FAIL state for node f16a0f69702d233768cec8075f6bdb8d7677c7fc: replica is reachable again.
1:M 18 Mar 2020 04:35:36.373 * Clear FAIL state for node 07358e9560cb6059495fbaf2bf6b831695920b6e: replica is reachable again.
1:M 18 Mar 2020 04:35:37.243 * Clear FAIL state for node 89136814ea739a99417054dbf41ea0ded4817909: master without slots is reachable again.
1:M 18 Mar 2020 04:35:40.676 # Failover auth granted to 5e79d143e1773f99d92c5acb70ccda5a38dfd19f for epoch 21
1:M 18 Mar 2020 04:35:41.807 * Clear FAIL state for node eb97b4baffba703c1a0b106c8c26c8aeb122c114: is reachable again and nobody is serving its slots after some time.
1:M 18 Mar 2020 04:35:41.807 # Cluster state changed: ok
1:M 18 Mar 2020 04:35:43.789 # Failover auth denied to 07358e9560cb6059495fbaf2bf6b831695920b6e: its master is up
1:M 18 Mar 2020 04:35:44.706 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b
1:M 18 Mar 2020 04:35:44.706 # Cluster state changed: fail
1:M 18 Mar 2020 04:35:46.033 # Failover auth granted to 89136814ea739a99417054dbf41ea0ded4817909 for epoch 23
1:M 18 Mar 2020 04:35:48.171 # Cluster state changed: ok
1:M 18 Mar 2020 04:35:50.686 * Clear FAIL state for node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b: replica is reachable again.
1:M 18 Mar 2020 04:35:58.734 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b
1:M 18 Mar 2020 04:35:59.239 * Clear FAIL state for node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b: replica is reachable again.
1:M 18 Mar 2020 04:36:29.901 # Failover auth denied to f16a0f69702d233768cec8075f6bdb8d7677c7fc: reqEpoch (17) < curEpoch(23)
1:M 31 Mar 2020 11:07:45.284 # Bad message length or signature received from Cluster bus.
1:M 05 Apr 2020 16:49:41.276 # Bad message length or signature received from Cluster bus.
1:M 05 Apr 2020 17:11:55.117 # Bad message length or signature received from Cluster bus.
1:M 06 Apr 2020 12:35:47.580 # Bad message length or signature received from Cluster bus.
1:M 06 Apr 2020 12:51:34.356 # Bad message length or signature received from Cluster bus.
1:M 07 Apr 2020 07:45:42.682 # Bad message length or signature received from Cluster bus.
1:M 08 Apr 2020 05:34:09.540 # Cluster state changed: fail
1:M 08 Apr 2020 05:34:19.380 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 53cbf4b5efdef7e11e54519a22ce0237989e80b5
1:M 08 Apr 2020 05:34:20.178 # Failover auth denied to 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: its master is up
1:M 08 Apr 2020 05:34:20.815 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 5e79d143e1773f99d92c5acb70ccda5a38dfd19f
1:M 08 Apr 2020 05:34:21.014 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 07358e9560cb6059495fbaf2bf6b831695920b6e
1:M 08 Apr 2020 05:34:21.014 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 89136814ea739a99417054dbf41ea0ded4817909
1:M 08 Apr 2020 05:34:21.154 * FAIL message received from 89136814ea739a99417054dbf41ea0ded4817909 about 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b
1:M 08 Apr 2020 05:34:22.122 * Clear FAIL state for node 07358e9560cb6059495fbaf2bf6b831695920b6e: replica is reachable again.
1:M 08 Apr 2020 05:34:24.434 # Failover auth granted to 07358e9560cb6059495fbaf2bf6b831695920b6e for epoch 24
1:M 08 Apr 2020 05:34:26.337 * FAIL message received from 53cbf4b5efdef7e11e54519a22ce0237989e80b5 about 07358e9560cb6059495fbaf2bf6b831695920b6e
1:M 08 Apr 2020 05:34:27.366 # Failover auth granted to 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b for epoch 25
1:M 08 Apr 2020 05:34:32.629 * Clear FAIL state for node 53cbf4b5efdef7e11e54519a22ce0237989e80b5: is reachable again and nobody is serving its slots after some time.
1:M 08 Apr 2020 05:34:32.833 * Clear FAIL state for node 07358e9560cb6059495fbaf2bf6b831695920b6e: replica is reachable again.
1:M 08 Apr 2020 05:34:33.525 * Clear FAIL state for node 89136814ea739a99417054dbf41ea0ded4817909: is reachable again and nobody is serving its slots after some time.
1:M 08 Apr 2020 05:34:36.633 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:M 08 Apr 2020 05:34:37.207 * FAIL message received from 53cbf4b5efdef7e11e54519a22ce0237989e80b5 about eb97b4baffba703c1a0b106c8c26c8aeb122c114
1:M 08 Apr 2020 05:34:37.207 * FAIL message received from 53cbf4b5efdef7e11e54519a22ce0237989e80b5 about 5e79d143e1773f99d92c5acb70ccda5a38dfd19f
1:M 08 Apr 2020 05:34:38.352 * Clear FAIL state for node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b: replica is reachable again.
1:M 08 Apr 2020 05:34:38.997 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:M 08 Apr 2020 05:34:54.170 * Clear FAIL state for node eb97b4baffba703c1a0b106c8c26c8aeb122c114: is reachable again and nobody is serving its slots after some time.
1:M 08 Apr 2020 05:34:54.170 # Cluster state changed: ok
1:M 08 Apr 2020 10:22:33.906 # Bad message length or signature received from Cluster bus.
1:M 21 Apr 2020 08:09:48.647 # Bad message length or signature received from Cluster bus.
1:M 28 Apr 2020 12:26:56.440 # Bad message length or signature received from Cluster bus.
1:M 28 Apr 2020 21:54:50.107 # Bad message length or signature received from Cluster bus.
1:M 29 Apr 2020 13:11:16.860 # Bad message length or signature received from Cluster bus.
1:M 05 May 2020 09:16:23.750 # Bad message length or signature received from Cluster bus.
1:M 12 May 2020 02:33:05.872 # Cluster state changed: fail
1:M 12 May 2020 02:33:18.321 * Marking node f16a0f69702d233768cec8075f6bdb8d7677c7fc as failing (quorum reached).
1:M 12 May 2020 02:33:18.321 * Marking node 07358e9560cb6059495fbaf2bf6b831695920b6e as failing (quorum reached).
1:M 12 May 2020 02:33:19.915 # Failover auth denied to 07358e9560cb6059495fbaf2bf6b831695920b6e: its master is up
1:M 12 May 2020 02:33:20.223 * FAIL message received from 89136814ea739a99417054dbf41ea0ded4817909 about 5e79d143e1773f99d92c5acb70ccda5a38dfd19f
1:M 12 May 2020 02:33:20.430 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 89136814ea739a99417054dbf41ea0ded4817909
1:M 12 May 2020 02:33:20.932 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b
1:M 12 May 2020 02:33:21.545 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about 53cbf4b5efdef7e11e54519a22ce0237989e80b5
1:M 12 May 2020 02:33:21.565 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:M 12 May 2020 02:33:21.617 * Clear FAIL state for node 07358e9560cb6059495fbaf2bf6b831695920b6e: replica is reachable again.
1:M 12 May 2020 02:33:23.208 # Failover auth granted to 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b for epoch 27
1:M 12 May 2020 02:33:23.461 # Failover auth denied to 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: already voted for epoch 27
1:M 12 May 2020 02:33:23.546 * Clear FAIL state for node f16a0f69702d233768cec8075f6bdb8d7677c7fc: replica is reachable again.
1:M 12 May 2020 02:33:25.734 # Failover auth denied to f16a0f69702d233768cec8075f6bdb8d7677c7fc: its master is up
1:M 12 May 2020 02:33:29.012 * FAIL message received from eb97b4baffba703c1a0b106c8c26c8aeb122c114 about f16a0f69702d233768cec8075f6bdb8d7677c7fc
1:M 12 May 2020 02:33:29.297 * Clear FAIL state for node f16a0f69702d233768cec8075f6bdb8d7677c7fc: replica is reachable again.
1:M 12 May 2020 02:33:30.237 * Clear FAIL state for node 113b650fb7f5da2f31847a1efcd3c0148b1d9b4b: replica is reachable again.
1:M 12 May 2020 02:33:30.991 * Clear FAIL state for node 89136814ea739a99417054dbf41ea0ded4817909: is reachable again and nobody is serving its slots after some time.
1:M 12 May 2020 02:33:32.605 * Clear FAIL state for node 53cbf4b5efdef7e11e54519a22ce0237989e80b5: is reachable again and nobody is serving its slots after some time.
1:M 12 May 2020 02:33:34.494 # Connection with replica 211.159.216.48:6384 lost.
1:M 12 May 2020 02:33:34.966 # Configuration change detected. Reconfiguring myself as a replica of f16a0f69702d233768cec8075f6bdb8d7677c7fc
1:S 12 May 2020 02:33:34.967 * Before turning into a replica, using my master parameters to synthesize a cached master: I may be able to synchronize with the new master with just a partial transfer.
1:S 12 May 2020 02:33:34.967 # Cluster state changed: ok
1:S 12 May 2020 02:33:35.107 * Connecting to MASTER 211.159.216.48:6384
1:S 12 May 2020 02:33:35.107 * MASTER <-> REPLICA sync started
1:S 12 May 2020 02:33:35.108 * Non blocking connect for SYNC fired the event.
1:S 12 May 2020 02:33:35.109 * Master replied to PING, replication can continue...
1:S 12 May 2020 02:33:35.311 * Trying a partial resynchronization (request 38e8c796b3c1f838d766c5f075d2b36adf268ac5:6627195).
1:S 12 May 2020 02:33:35.312 * Successful partial resynchronization with master.
1:S 12 May 2020 02:33:35.312 # Master replication ID changed to bd6eab319118534aded9e9fd556e604087628e1b
1:S 12 May 2020 02:33:35.312 * MASTER <-> REPLICA sync: Master accepted a Partial Resynchronization.
1:S 12 May 2020 02:33:41.443 * FAIL message received from 89136814ea739a99417054dbf41ea0ded4817909 about 5e79d143e1773f99d92c5acb70ccda5a38dfd19f
1:S 12 May 2020 02:33:42.029 * Clear FAIL state for node 5e79d143e1773f99d92c5acb70ccda5a38dfd19f: replica is reachable again.
1:S 12 May 2020 02:34:00.973 # Cluster state changed: fail
1:S 12 May 2020 02:34:01.583 # Cluster state changed: ok
1:S 12 May 2020 02:37:16.568 # Cluster state changed: fail
1:S 12 May 2020 02:38:07.079 # MASTER timeout: no data nor PING received...
1:S 12 May 2020 02:38:07.103 # Connection with master lost.
1:S 12 May 2020 02:38:07.103 * Caching the disconnected master state.
1:S 12 May 2020 02:38:07.104 * Connecting to MASTER 211.159.216.48:6384
1:S 12 May 2020 02:38:07.104 * MASTER <-> REPLICA sync started
1:S 12 May 2020 02:39:08.725 # Timeout connecting to the MASTER...
1:S 12 May 2020 02:39:08.735 * Connecting to MASTER 211.159.216.48:6384
1:S 12 May 2020 02:39:08.736 * MASTER <-> REPLICA sync started
1:S 12 May 2020 02:40:09.453 # Timeout connecting to the MASTER...
1:S 12 May 2020 02:40:09.454 * Connecting to MASTER 211.159.216.48:6384
1:S 12 May 2020 02:40:09.454 * MASTER <-> REPLICA sync started
1:signal-handler (1589251211) Received SIGTERM scheduling shutdown...
1:S 12 May 2020 02:40:11.292 # User requested shutdown...
1:S 12 May 2020 02:40:11.293 * Calling fsync() on the AOF file.
1:S 12 May 2020 02:40:11.294 * Removing the pid file.
1:S 12 May 2020 02:40:11.321 # Redis is now ready to exit, bye bye...
